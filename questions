a) Consider the following transition probabilities and the reward for an MDP with states 1 and $2. Actions af and a2 are available in each of the states

Compute x as below. x (last digit of your student id +43% 20. No marks will be given for the use of any other Consider the initial values of st, s2, and s3 are 10, 1.0 and 0.0, respectively. Compute values of states after 2 iterations, given the discount factor as x using an asynchronous version of value iteration. Show all the computations 14 M What I will be the optimal policy after the two iterations 105 MI
